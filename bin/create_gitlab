#! /usr/bin/env python
# -*- coding: UTF8 -*-

# Keith Jolley
# Sat Feb  9 05:11:45 PST 2019

# Main program for bringing up a Gitlab environment

# Tested with python3.6/7 on Linux and Darwin
# You must run this progam in the same directory as the source data.
# Requires:
#   terraform: conda or https://www.terraform.io/downloads.html
#   ansible: conda or https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html

# !Standard library
import boto3

# Standard library
import re
import os
import sys
import stat
import time
import string
import argparse
import datetime
import platform
import subprocess
import configparser
from random import choice
from pathlib import Path

# Note that changing versions will cause all (most) resources to be rebuilt.
VERSION = "0.1"
VERBOSE = True

parser = argparse.ArgumentParser(description='Install some Gitlab.')
parser.add_argument('-r', '--region', help='region to build the environment') 
parser.add_argument('-p', '--profile', 
    help='EC2 profile to use. Will look for credentials in ~/.aws/credentials_`profile`.')
parser.add_argument('-d', '--destroy', action='store_true', help='Safely bring everything down.')
parser.add_argument('--version', action='version', version=VERSION)
parser.add_argument('--gitlab_app_server_ami_id', action='gitlab_app_server_ami_id',
    help='AMI ID of the Gitlab server image in the region.')
#parser.add_argument('--verbose', action='store_true', help='Not yet implemented')
#parser.add_argument('--domainname', help='Not yet implemented.')
#parser.add_argument('--subdomainname', help='Not yet implemented.')

args = parser.parse_args()
region = args.region
profile = args.profile
gitlab_app_server_ami_id = args.gitlab_app_server_ami_id
destroy = args.destroy

# Directory structure
#   configuration/[terraform,ansible]
#   destination_region/[terraform,ansible]
# Runs terraform in `terraform` sub-dir.
# Absolute paths haven't been tested.
source_dir = "./configuration"
destination_dir = "./environment"
terraform = "terraform"

USERNAME = "centos"
BASTION_HOSTNAME = "bastion"
DOMAINNAME = "jamulheavyindustries.com"
POSTGRES_PW_FILE = "postgres_password.txt"

# These ansible roles are required to configure the NFS server.
# Will attempt to install if not already.
ANSIBLE_ROLES = ['geerlingguy.nfs', 'aloisbarreras.ebs-raid-array']

# Note that this is a private AMI and AWS prevents me from sharing.
# Fully automating creating an AMI at runtime added more run-time and
# complexity for this script than I thought was good for a demo.
# "Decisions were made."
#
# The terraform rules are in in place, but commented out, for creating
# the needed AMI.
#
# To make your own AMI:
#
#   % cd environment-`region`/terraform/ (assuming you've already run this program)
#   Uncomment the 'replicant_0' rule in `environment-`region`/terraform/main.tf`,
#   % terraform apply
#   Stop the new 'replicant_0' instance.
#   Create an AMI.
#   Change the next three lines to reflect your new "replicant_zero" AMI.
#   Rerun this program to propagate these changes into your environment.
#   Once this step is done once your new AMI will be copied into any regions
#   as needed.

def inform(message, fatal=0):
    """
    Prints 'code: me: message' to stderr.
    If fatal>0 then `code` is "ERROR" and exits with code.
    If fatal=0 then `code` is "NOTE" and function returns.
    All `fatal` messages are printed, else only if VERBOSE.
    """
    code = "ERROR:" if fatal else "NOTE: "
    message = re.sub("^|\n", "\n{} {}: ".format(code, me), message).lstrip()
    if fatal:
        print(message, file=sys.stderr)
        sys.exit(fatal)
    if VERBOSE:
        print(message, file=sys.stderr)
    return

# Various messages should this go pear shaped.
REGION_FINDER = """Valid regions can be found with:
% aws ec2 describe-regions --query "Regions[].{Name:RegionName}" --output text | sort

Their geographic locations are listed here:
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html"""

TERRAFORM_MESSAGE = """Terraform needs to be installed. It can be downloaded here:
https://learn.hashicorp.com/terraform/getting-started/install.html
Or with conda:
conda install -c conda-forge terraform
Terraform is a binary. It can be installed in '{}'"""

ANSIBLE_MESSAGE = """Ansible needs to be installed. It can be downloaded here:
https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html
Or with conda:
conda install -c conda-forge ansible"""


def usage(res):
    message = """USAGE: '{} aws-region'

Creates a GitLab instance in 'aws-region'.
Requires the `boto3` python package.

Assumes you have terraform and ansible in your
path and you can otherwise run aws commands.

Required keys are in ~/.aws - created if needed.

Looks in PATH and "./bin/{}/" for terraform.

{}""".format(me, platform.system(), REGION_FINDER)
    inform(message)
    sys.exit(res)
    return


def check_keypair(profile, client, resource, region):
    """
    Ensures there's a valid keypair in the region AND a pem file.
    Halts if not.
    """
    inform("Checking for key-pair '{}' in '{}'.".format(profile, region))
    pem_dir = Path('~', '.aws').expanduser()
    pem_file = Path(pem_dir, 'secret_' + profile + '.pem')
    pub_file = Path(pem_dir, 'secret_' + profile + '.pub')

    def make_pub_file():
        with open(pub_file, "w") as f:
            subprocess.call(["ssh-keygen", "-y", "-f", pem_file], stdout=f)
        os.chmod(pem_file, 0o600)

    if pem_file.exists() and not pub_file.exists(): make_pub_file()

    try:
        response = client.describe_key_pairs(KeyNames=[profile])
    except boto3.exceptions.botocore.exceptions.EndpointConnectionError:
        inform("Couldn't verify key-pair for region '" + region + "'\n"
             + "This probably means you don't have a valid region.\n"
             + REGION_FINDER, 4)
    except boto3.exceptions.botocore.exceptions.ClientError:
        # No key. Try to create one and a pem file.
        error = sys.exc_info()[1]
        if('Error' in error.response
                and 'Code' in error.response['Error']
                and error.response['Error']['Code'] == 'InvalidKeyPair.NotFound'):
            inform("The keypair '{}' was not found. Attempting to create." .format(profile))
            if pub_file.exists():
                # Upload the public key (good if you don't trust Amazon to create a pub key)
                try:
                    with open(pub_file) as f:
                        pub_key_data = f.read()
                    response = client.import_key_pair(
                                    KeyName=profile,
                                    PublicKeyMaterial=pub_key_data)
                except:
                    inform("Failed to import public key: '{}'.\n{}".format(pub_file, sys.exc_info()[1]), 17)
            elif not pem_file.exists():
                try:
                    key_pair_response = resource.create_key_pair(KeyName=profile)
                    with open(pem_file, 'w') as f:
                        f.write(str(key_pair_response.key_material))
                    os.chmod(pem_file, 0o600)
                    make_pub_file()
                except:
                    inform("Failed creating a new keypair:\n{}".format(sys.exc_info()[1]), 6)
            else:
                inform("I'm out of options on how to proceed wrt to pem/pub key files. Punting.", 18)
        else:
            inform("Unexpected error key pairs:\n{}".format(sys.exc_info()[1]), 7)
    #else:
    #    inform("Unexpected error getting key pairs:\n{}".format(sys.exc_info()[1]), 8)
    if not pem_file.exists():
        inform("Expected a pem file here: {}".format(pem_file), 10)
    return pem_file


def parse_source_data(data, subs):
    """
    Inserts a prefix where ever `__PREFIX__` is found
    Prefix converts `subs` into terraform vars:
    variable "key" { default = "value" }
    """
    # This replaces the following code.
    #"""
    #Replace all $(_KEY_) with VALUE in data. Yes, this is clunky.
    #First re finds all the $(_keys_) in the data.
    #Second re replaces key -> value in `subs`.
    #"""
    #data_re = re.compile('(\$\(_(' + '|'.join(map(re.escape, subs)) + ')_\))')
    #key_re = re.compile(r'^\$\(_([^_]*)_\)$')
    #return data_re.sub(lambda x: subs[key_re.sub("\g<1>", x.group(0))], data)
    #
    # I think this is a little cleaner, maintainable, and nearer to what terraformers
    # would bless. Maybe even just a separate vars file would be better?
    prefix = "\n".join([('variable "{}" {} default = "{}" {}'.format(k,"{",v,"}"))
                    for k,v in subs.items()])
    return re.sub(r'(?m)^__PREFIX__$', prefix, data)


def create_source_data(source, destination, subs):
    """
    Parses config inputs -> destination.
    Recursively goes through entire source.
    All files in source overwrite existing file in destination
    but any other file (state files) in destination are left
    alone. In theory terraform is smart enough to only update
    the deltas.
    """
    inform(("$"*80) + ("$"*80))
    srcdir = Path(source).resolve()
    dstdir = Path(destination).resolve()
    Path(dstdir).mkdir(parents=True, exist_ok=True)

    inform("Creating source data.")
    if not srcdir.exists():
        inform("Source directory is missing: '{}'".format(srcdir), 11)
    src_re = re.compile('^' + str(srcdir) + '/')
    for src in srcdir.glob('**/*'):
        dst = src_re.sub(str(dstdir) + '/', str(src))
        if Path(src).is_dir():
            # Make sure the destination directory exists
            Path(dst).mkdir(parents=True, exist_ok=True)
        else:
            # Parse this file and put the output in destination
            if re.match("\.", src.name):
                # Skip hidden files (in particular *.swp)
                inform("Skipping '{}'. It will not be copied to '{}'.".format(src, dstdir))
            else:
                inform("'{}' -> '{}'".format(str(src), dst))
                with open(src, 'r') as f:
                    data = parse_source_data(f.read(), subs)
                with open(dst, 'w') as f:
                    f.write(data)
    return dstdir


def run_cmd(*cmd):
    cmdstr = " ".join(cmd)
    inform("Running command: '{}':".format(cmdstr))
    try: subprocess.run(cmd, check=True)
    except Exception as error:
        inform("Problem running '{}':\n{}".format(cmdstr, error), 12)
    return


def run_terraform(terraform_dir, build):
    """
    Runs terraform commands to cleanly bring everything up.
    """
    if not Path(terraform_dir).exists():
        inform("Terrform directory hasn't been configured: {}".format(terraform_dir), 20)
    inform("Changing directory to '{}':".format(terraform_dir))
    os.chdir(terraform_dir)
    if build:
        # Sometimes having a list of things you are going to do
        # is easier to grok than comprehensions.
        run_cmd("terraform", "init")
        run_cmd("terraform", "get")
        run_cmd("terraform", "apply", "--auto-approve")
    else:
        run_cmd("terraform", "destroy")
    return


def subdomain(region):
    return re.sub(r"[\.\s]", "-", 'gitlab ' + region)


def fqdn(hostname, region):
    return ".".join([hostname, subdomain(region), DOMAINNAME])


def update_path():
    # Put './bin/SYSTEM' in the path. (hack)
    # Keep Linux/Darwin terraform executables in there.
    # I don't like this but the alternative is to force the user
    # to install a program they may not want to keep around and/or
    # update their path every time they want to run this script.
    local_path = str(Path(Path.cwd(), "bin", platform.system()))
    inform("Appending '{}' to your PATH".format(local_path))
    if local_path not in os.environ["PATH"].split(':'):
        os.environ["PATH"] += ":" + local_path
    return local_path


def ansible_prereqs(roles):
    ansible_out = subprocess.run(['ansible-galaxy', 'list'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    for role in roles:
        if re.search(role, str(ansible_out.stdout)):
            inform("Ansible role '{}' already installed.".format(role))
        else:
            inform("Installing ansible role: '{}'.".format(role))
            subprocess.run(['ansible-galaxy', 'install', role])
    return


def check_program(program, message):
    """
    See if we have access to an executable.
    """
    inform("Checking for '{}' executable:".format(program[0]))
    try:
        subprocess.run(program, check=True)
    # Can't find program
    except FileNotFoundError:
        inform("Can't find '{}'. Is it installed and in your path?\n{}"
            .format(program[0], message), 15)
    # Can't run the program I found
    except:
        inform("Can't run '{}'. Is the correct system type first in your $PATH?\n{}"
            .format(program[0], message), 16)
    return


def get_availability_zones(resource):
    """
    Returns two availability zones that are available in the region of interest.
    Here's a fun fact. An availablity zone is a complete abstraction. Different
    accounts will not only see different availability zones that are available 
    for them to use, but, even the same named availability zone, for instance 
    `us-west-1a`, might be, in reality, a different `zone` for one account than
    another. Regardless, one can't count on always having the same suffix available
    all the time. This is where we collect two zones that are available to us
    right now.
    """
    response = resource.describe_availability_zones(Filters=[{"Name": "state", "Values": ["available"]}])
    if 'AvailabilityZones' not in response:
        inform("Not able to retrieve availability zones in '{}'".format(region), 13)
    # Return the two last (probably of two) zones lists.
    return [az['ZoneName'] for az in response['AvailabilityZones']][-2:]


def create_password(length):
    alphabet = string.ascii_letters + string.digits
    while True:
        password = ''.join(choice(alphabet) for i in range(length))
        if (any(c.islower() for c in password)
            and any(c.isupper() for c in password)
            and sum(c.isdigit() for c in password) >= 3):
            break
    return password


def create_postgres_password(length, path):
    path = Path(path, POSTGRES_PW_FILE)
    if path.exists():
        inform("Using postgres password from '{}'.".format(str(path)))
        with open(path) as f:
            password = f.read()
    else:
        inform("Creating postgres password, saving into file: '{}'.".format(str(path)))
        password = create_password(length)
        with open(str(path), 'w') as f:
            f.write(password + '\n')
    return password.rstrip()


if __name__ == "__main__":

    # Name of this script
    me = Path(sys.argv[0]).name

    # Make sure we have required programs in PATH
    local_path = update_path()
    requirements = (
        (('terraform', '-version'), TERRAFORM_MESSAGE.format(local_path)),
        (('ansible-galaxy', '--version'), ANSIBLE_MESSAGE),
        (('ansible-playbook', '--version'), ANSIBLE_MESSAGE),
    )

    [check_program(program, message) for program, message in requirements]

    destination_dir += "_" + region
    terraform_dir = Path(destination_dir, terraform)

    Path(destination_dir).mkdir(parents=True, exist_ok=True)

    # Minimum required to bring down the env.
    if destroy:
        run_terraform(terraform_dir, False)
        sys.exit(0)

    # Make sure the required ansible modules are installed.
    ansible_prereqs(ANSIBLE_ROLES)

    # Not sure that there's any advantage to re-using the
    # same client/resoruce through the entire program.
    client = boto3.client('ec2', region_name=region)
    resource = boto3.resource('ec2', region_name=region)

    # Makes sure we can do things in this region and
    # ensures we have a valid pem file. Dead in the water
    # without this being successful.
    pem_file = check_keypair(profile, client, resource, region)

    # Find two availability zones to use.
    availability_zones = get_availability_zones(client)
    inform("availability_zones: {}".format(availability_zones))

    postgres_password = create_postgres_password(12, destination_dir)

    # Clunky list of substitutions to make in the config files
    # $(_key_) -> value
    subs = {
        "availability_zone_0": availability_zones[0],
        "availability_zone_1": availability_zones[1],
        "bastion_fqdn": fqdn(BASTION_HOSTNAME, region),
        "bastion_hostname": BASTION_HOSTNAME,
        "date": str(datetime.datetime.now().isoformat()),
        "domainname": DOMAINNAME,
        "gitlab_application_ami": gitlab_app_server_ami_id,
        "keypair": profile,
        "me": me,
        "pemfile": str(pem_file),
        "postgres_password": postgres_password,
        "prefix": profile,
        "profile": profile,
        "region": region,
        "subdomainname": subdomain(region),
        "username": USERNAME,
        "version": VERSION
    }
    # Parse all the input files and place them
    # in subdirs within `destination+region`
    create_source_data(source_dir, destination_dir, subs)

    # Run terraform
    run_terraform(terraform_dir, True)

    # What we've all been waiting for.
    boot_ssh_cmd = ["ssh", "-A",
                     USERNAME + "@" + fqdn(BASTION_HOSTNAME, region)]
    inform(
"""You should be able to login to the bastion host now:

{}

Sometimes DNS entries take a few moments to propagate...
If you get access denied be sure that you have your original
credentials in your keychain. Check with `ssh.add -l`. 

VERY IMPORTANT! Your unique Postgres password is in two places,
both of them on this host ONLY. One is in the terraform
configuration file in '{}', the other is
in this text file here: {}

If you plan on keeping this Gitlab environment around please
copy it to somewhere safe.

""".format(" ".join(boot_ssh_cmd), terraform_dir,
                str(Path(destination_dir, POSTGRES_PW_FILE))))

# Some nice to have haves:
#
#   --domain/subdomain 'name'
#     To use a different subdomain.domain. Right now only one instance
#     can exist at a time because of dns collision. Also, other accounts
#     can't (I hope!) modify my domains.
#
#   --profile profile
#     should be optional, instead figure out from the environment what 
#     profile to use.
# 
